# 기계학습 3주차 정리노트

201703205 김현준 202184032 안신영

<안신영>

회귀: 다중 회귀, 단변량 회귀가 있다.

훈련 데이터와 테스트 데이터가 지금 겹치게 되면 데이터 분석이 망하게 되니까 다른 경로를 만들어서 같은 경로로 갈 수 있을 것 같다.

무작위 → 모든 것들을 제대로 특정할 수 없다.

계층적→ 단계별로 가져오는 것이 깔끔하고 정확하게 가져올 수 있을 것 같아서 계층적이 좀 더 체계화 되어있을 것 같다. 

문제점:  특정한 것들만 가져올 수 있다.

<김현준>

데이터 스펙트럼을 넓히는게 기반이되고 평균이 만들어지고 툴이 넓어지니까 더 많은 데이터를 가져올 수 있을 것 같다. 학습을 진행할 때 가중치를 변화시키는 것도 괜찮을 것 같다.

무작위 → 표본집단을 제대로 대표할 수 없다.

계층적 → 실제 데이터하고 멀어질 수 있다.

<질문>

가중치를 왜 변화시키는 것이 좋다고 생각했나?

→ 가중치를 적게 설정하면 학습률이 줄어들기 떄문에 한번 학습영향이 줄어든다.

데이터를 왜 크게 만들까요?

→ 데이터를 크게 만들면 괜찮지 않을까?

왜 실제 데이터하고 멀어질 수 있을까?

→ 실제로 어떤 두 가지 계층은 그대로 가져오는데 무작위는 그래도 하나라도 가져온다고 답변을 받았다.

<정리>

일반화가 되지않는다. 전국적으로 보여주려면 계층적으로 써야한다. 전체적인 비율을 가져올 수 있다.

테스트데이터를 만들 때 이러한 것들을 주의해야한다.

데이터 전처리가 중요하다. → 모델 학습을 효율적으로 진행하기 위해서는 전처리를 해야한다.

원 - 핫 인코딩 → 해당 카테고리 특성 1, 나머지 카테고리 특성값 0  두가지 밖에 없다.

모델을 훈련할 수 있게 전처리 과정을 함 
-> 모델을 선택하고 평가를 함 -> 선형회귀 모델
