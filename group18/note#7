# 기계학습 정리노트 10주차

201703205 김현준 202184032 안신영

<정리>

차원축소 - 특성 수를 줄여서 학습 불가능한 문제를 만든다.

숫자를 분별하는 것 샘플 특성이 많을 수록 학습이 어렵다. 차원을 축소를 시켜야된다.

데이터를 채우거나, 차원을 줄이거나 데이터를 확보하기 어렵다. 

일부 정보가 유실될 수 있다. 

투영)

데이터가 있는 쪽을 투영을 해서 차원을 줄인다.  → 방법1 투영, 방법2 매니폴드학습

3차원공간을 2차원으로 투영을 한다. 

합리적인 축을 찾아야한다. 

투영이 최선의 방법은 아니다. 서로 뭉개지기도 하기도 하기 떄문이다. 

매니폴드 학습)

스위스 롤 중에 하나이다. 고차원 공간에서 휘어지거나 뒤틀린 모양이다. 

짧은 부분이 d차원 초평면으로 보일 수 있는 n차원 공간의 일부이다. 

고차원 데이터셋이 더 낮은 저차원 매니폴드에 가깝게 놓여 있있다는 매니폴드를 가정에 근거함 → 항상 그러하지않음

3차원에서는 분류가 가능하지만 차원을 감소하면 분류가 더 어렵게 된다. → 더 나은 해결책이 될 수는 없음 

축을 제일 먼저 찾기 

pca → 주성분 분석은 가까운 초평면을 정의한 다음, 데이터를 평면에 투영시킴

분산이 최대로 보존되어야 정보가 가장 적게 손실된다. 

분산이 작다는 것은 데이터가 뭉쳐있다는 것

주성분찾기 : 소프트에서 찾는 방법 svd 사용

적절한 차원 수를 선택하는 것이 충분한 분산(95%)이 되도록하는 차원의 수를 선택한다.

분산을 유지하려면(95%)정도 주성분만 사용하면 됨

점진적 PCA → 온라인학습에 가능하다. 점진적으로 주입함 , partial_fit()으로 선언함

커널과 하이퍼파라미터 → 그리드 탐색, 재구성 원상의 오차를 초소화하는 방법을 선택할 수 있는 방법

LLE 의 key idea : 투영으로 했을 경우는 뭉개지고, 지금은 차원을 펴서 구분한다. 가장 가까운 이웃에 선형적으로 연관되어 있는지 측정, 잡음이 많지 않을 경우에 꼬인 매니폴드를 펼치는데 작동

<질문>

투영과 매니폴드학습의 차이점?

머신러닝에서 투영(Projection)과 매니폴드 학습(Manifold Learning)은 데이터를 시각화하거나 차원 감소를 수행하는 데 사용되는 두 가지 다른 접근 방식입니다. 다음은 두 방법의 주요 차이점을 설명합니다:

1. 투영(Projection):
    - 투영은 데이터를 고차원 공간에서 저차원 공간(주로 2D 또는 3D)으로 변환하는 것을 의미합니다. 이를 통해 데이터의 구조를 보다 간단하게 시각화하거나 차원 감소를 수행할 수 있습니다.
    - 주로 주성분 분석(PCA)과 같은 기법을 사용하여 가장 중요한 축을 찾아 데이터를 저차원 공간으로 투영합니다. PCA는 주성분(Principal Component)을 찾아서 데이터의 분산을 최대화하는 방향으로 투영합니다.
2. 매니폴드 학습(Manifold Learning):
    - 매니폴드 학습은 데이터가 실제로 고차원 공간에서 낮은 차원의 매니폴드(다양체)에 존재한다고 가정하고, 이 매니폴드의 구조를 추출하려는 방법입니다.
    - 매니폴드 학습은 데이터가 비선형적으로 분포할 때 유용하며, 주로 지역적 구조(local structure)와 클러스터(cluster)를 보존하려는 노력이 포함됩니다. 대표적인 예로 t-SNE(t-Distributed Stochastic Neighbor Embedding)나 Isomap 등이 있습니다.

주요 차이점:

- 투영은 데이터를 고차원 공간에서 저차원 공간으로 변환하는 방법으로 주로 선형적인 방식을 사용합니다. 반면 매니폴드 학습은 데이터가 비선형적으로 분포할 때 유용하며 매니폴드의 지역적 구조를 보존하려는 노력이 포함됩니다.
- 투영은 주로 주성분 분석(PCA)과 같은 선형 기법을 사용하고, 결과는 주로 저차원 공간에서 데이터 포인트 간의 거리를 보존합니다. 매니폴드 학습은 데이터의 비선형 구조를 보존하려는 비선형 기법을 사용합니다.
- 투영은 주로 차원 감소와 데이터 시각화에 사용되며 데이터의 주요 구조를 유지하기 위한 목적이 강조됩니다. 매니폴드 학습은 데이터의 매니폴드 구조 자체를 추출하려는 목적이 강조됩니다.

어떤 방법을 사용해야 하는지는 데이터의 특성과 목표에 따라 다릅니다. 선형적인 데이터 분포에 대해서는 투영이 효과적일 수 있고, 비선형적인 데이터 분포에 대해서는 매니폴드 학습이 더 적합할 수 있습니다.

<질문2>

PCA가 정확히 무엇인지? 

PCA(Principal Component Analysis)는 다차원 데이터를 저차원으로 축소하는 방법 중 하나로, 데이터의 주요 특성을 추출하거나 데이터를 시각화하는 데 사용되는 통계적 기술입니다. PCA는 다차원 데이터의 차원을 줄이고, 데이터의 주성분(Principal Component)을 찾아내는데 유용하며, 주요 정보를 보존하면서 노이즈를 제거할 수 있습니다.

PCA의 주요 단계는 다음과 같습니다:

1. 데이터 표준화: PCA를 적용하기 전에 데이터를 평균이 0이고 표준편차가 1인 형태로 표준화합니다. 이는 데이터 스케일을 맞추는 과정이며, 다차원 데이터의 각 변수들을 동등한 중요도로 다루기 위함입니다.
2. 공분산 행렬 계산: 표준화된 데이터를 기반으로 공분산 행렬을 계산합니다. 공분산 행렬은 데이터의 변수 간 상관 관계를 나타내며, PCA는 이러한 상관 관계를 이용하여 데이터를 변환합니다.
3. 고유값과 고유벡터 계산: 공분산 행렬의 고유값(eigenvalue)과 고유벡터(eigenvector)를 계산합니다. 고유값은 데이터의 주성분의 중요도를 나타내며, 고유벡터는 주성분의 방향을 나타냅니다.
4. 주성분 선택: 고유값을 내림차순으로 정렬하여, 주성분을 선택합니다. 주성분은 데이터를 가장 잘 설명하는 방향을 나타냅니다.
5. 데이터 변환: 선택한 주성분을 이용하여 데이터를 저차원으로 변환합니다. 이를 통해 다차원 데이터를 주요 주성분으로 표현할 수 있습니다.

PCA를 사용하면 데이터의 차원을 줄이고 주요 정보를 추출할 수 있으며, 데이터 시각화, 노이즈 제거, 데이터 압축, 차원 감소, 패턴 인식 및 기계 학습 모델 성능 향상 등 다양한 응용 분야에서 사용됩니다.
