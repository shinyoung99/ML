# 기계학습 11주차 정리노트

201703205 김현준 202184032 안신영

<질문>

k-++평균은 정확히 무엇인가?

"K++"는 일반적으로 머신러닝이나 프로그래밍과 직접적으로 관련이 있는 용어가 아닙니다. 아마도 혼동이 있거나 잘못된 용어일 수 있습니다. "K++"에 대한 더 많은 정보나 문맥을 제공할 수 있으면 도움이 될 것입니다.

만약 "K++"가 어떤 특정 문맥에서 사용되었거나 특별한 의미를 가진 경우, 그 문맥이나 배경 정보를 알려주시면 더 정확한 도움을 드릴 수 있을 것입니다.

이너셔 개념과 미니배치를 비교하였을 때 어떤 것이 더욱 효과적일까?

이너셔(Inertia)와 미니배치(Mini-batch)는 각각 클러스터링 및 머신러닝의 다양한 알고리즘에서 사용되는 용어입니다. 그러나 이 두 용어 간에 직접적인 비교를 하기는 어렵습니다. 각각의 개념이 서로 다른 문맥에서 사용되기 때문입니다.

1. **이너셔(Inertia):**
    - 이너셔는 클러스터링에서 K-평균 알고리즘 등에서 사용되는 개념으로, 클러스터 내의 데이터 포인트들이 얼마나 서로 가까운지를 나타냅니다. 이 값이 작을수록 클러스터 내의 데이터 포인트들이 서로 가깝다는 의미이며, 일반적으로 클러스터링의 성능을 나타내는 지표 중 하나입니다.
2. **미니배치(Mini-batch):**
    - 미니배치는 주로 경사 하강법(Gradient Descent)을 포함한 최적화 알고리즘에서 사용되는 용어입니다. 전체 데이터셋을 한 번에 처리하는 대신, 작은 미니배치로 나누어 학습을 수행하는 것을 의미합니다. 이는 메모리 사용량을 줄이고 계산을 병렬로 수행할 수 있게 해줍니다. 미니배치 학습은 대규모 데이터셋에서 효율적으로 모델을 학습할 수 있는 방법 중 하나입니다.

따라서 "이너셔"와 "미니배치"는 서로 다른 맥락에서 사용되는 용어이며, 직접적인 비교는 어렵습니다. 특정 문제나 알고리즘에 따라 각각의 사용이 적절하며, 성능을 평가하기 위해서는 해당 알고리즘이나 작업의 목적과 요구 사항을 고려해야 합니다.

<정리>

비지도 학습

"얀 르쿤" 왈,

"비지도 학습은 케이크의 빵, 지도 학습은 크림, 강화 학습은 체리"

군집

비슷한 경향을 보이는 그룹끼리 묶는다.

*K평균* 집단의 중심이 되는 centroid를 중심으로 묶는다.

기본 개념

"K-평균 알고리즘은 가장 빠르고 가장 간단한 군집 알고리즘 중 하나로, 먼저 k 개의 센트로이드를 랜덤하게 초기화한뒤, 데이터셋에서 k 개의 샘플을 랜덤하게 선택하고 센트로이드를 그 위치에 놓습니다.
그 후로는 수렴할 때까지 다음을 반복합니다(센트로이드가 더이상 이동하지 않을 때까지)
* 각 샘플을 가장 가까운 센트로이드에 할당합니다.
* 센트로이드에 할당된 샘플의 평균으로 센트로이드를 업데이트합니다.

*결정 경계* centroid가 중요!

@하드 군집
@소프트 군집

이상치 탐지

표본 집합의 경향성에서 벗어난 이상치를 탐지한다.

이너셔

최선의 모델을 선택하려면 K-평균 모델의 성능을 평가할 방법이 있어야 합니다. 안타깝지만 군집은 비지도 학습이기 때문에 타깃이 없습니다. 하지만 적어도 각 샘플과 센트로이드 사이의 거리는 측정할 수 있습니다. 이것이 *이너셔* 지표의 아이디어입니다:

이너셔값을 알고싶을 때 Score()를 쓴다. 

알칸알고리즘: 불필요한 거리 계산을 피하고, 삼각함수를 통해서 학습속도를 향상시키기 위한 알고리즘이다. 

미니배치: 전체 데이터셋을 사용하는 것을 대신해서 미니배치릂 사용한다. 전체적인 통계를 구하는 것이 아니라 센트로잇을 이동시키는 방법이다. 미니배치 평균이 더 빠르다. 이니셔 값은 더 나쁘게 나온다. k- 평균 알고리즘보다 훨씬 빠르다.

관성과 클러스터 : K가 증가할 수록 관성이 작아진다, 좋은 지표는 아님

실루엣 → 칼모양 칼 두께가 많은 샘플들이 들어가겠다, 길이는 실루엣 계수 길어야 좋다. 

이너셔값으로는 충분하지 않다.

실루엣 계수는 수식이 따로 있다. (𝑏−𝑎)/max(𝑎,𝑏)

<실습>
